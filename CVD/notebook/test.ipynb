{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac6dcb1-c4d3-46c5-a093-76e596af3cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Prediction Probabilities: [0.9969031]\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('models/computer_cnn_model.keras')\n",
    "\n",
    "# Load the scaler\n",
    "with open('models/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Define a random input sample\n",
    "# Example: Randomly generated values for a feature vector (adjust these values to your dataset range)\n",
    "random_sample = np.array([[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]])  \n",
    "\n",
    "# Scale the input using the same scaler used during training\n",
    "random_sample_scaled = scaler.transform(random_sample)\n",
    "\n",
    "# Reshape for the CNN model (3D input: samples, features, 1)\n",
    "random_sample_scaled = random_sample_scaled.reshape(random_sample_scaled.shape[0], random_sample_scaled.shape[1], 1)\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(random_sample_scaled)\n",
    "\n",
    "# Interpret the prediction\n",
    "predicted_class = (prediction.flatten() > 0.5).astype(int)\n",
    "\n",
    "print(\"Prediction Probabilities:\", prediction.flatten())\n",
    "print(\"Predicted Class:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6961c2c-a737-4981-8f8f-7b792c0e6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding Layer\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, embed_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.pos_encoding = self.positional_encoding(max_len, embed_dim)\n",
    "\n",
    "    def positional_encoding(self, max_len, embed_dim):\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(embed_dim)[np.newaxis, :]\n",
    "        angle_rads = pos / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "    def get_config(self):\n",
    "            config = super(PositionalEncoding, self).get_config()\n",
    "            config.update({\n",
    "                \"max_len\": self.max_len,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            })\n",
    "            return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07cff711-618b-46eb-a4d1-d6999848a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(\"models/kaggle_transformer_model.keras\", compile=False)\n",
    "\n",
    "# Prepare the input data\n",
    "data = np.array([63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1])\n",
    "data = data.reshape(1, -1, 1)  # Reshape for model input [batch_size, sequence_length, feature_dim]\n",
    "\n",
    "# Make the prediction\n",
    "prediction_proba = loaded_model.predict(data).flatten()\n",
    "prediction = (prediction_proba > 0.3).astype(int)\n",
    "\n",
    "print(\"Prediction Probability:\", prediction_proba[0])\n",
    "print(\"Predicted Class:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9674d699-e8a9-4443-9ba6-0247e56df36d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x0b'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     scaler = pickle.load(f)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mmodels/lgbm_model.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     lgbm_model = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Sample test input (13 features)\u001b[39;00m\n\u001b[32m     13\u001b[39m test_input = np.array([[\u001b[32m52\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m125\u001b[39m, \u001b[32m212\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m168\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]])\n",
      "\u001b[31mUnpicklingError\u001b[39m: invalid load key, '\\x0b'."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the saved scaler and model\n",
    "with open('models/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('models/lgbm_model.pkl', 'rb') as f:\n",
    "    lgbm_model = pickle.load(f)\n",
    "\n",
    "# Sample test input (13 features)\n",
    "test_input = np.array([[52, 1, 0, 125, 212, 0, 1, 168, 0, 1.0, 2, 2, 3]])\n",
    "\n",
    "# Preprocess input\n",
    "test_input_scaled = scaler.transform(test_input)\n",
    "\n",
    "# Predict\n",
    "probabilities = lgbm_model.predict_proba(test_input_scaled)[:, 1]\n",
    "predictions = (probabilities > 0.5).astype(int)\n",
    "\n",
    "# Output results\n",
    "print(f\"Probability of Heart Disease: {probabilities[0]:.4f}\")\n",
    "print(f\"Prediction: {'Heart Disease' if predictions[0] == 1 else 'No Heart Disease'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fa5db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (LGBM): Heart Disease\n",
      "Prediction Probability (LGBM): [0.00215327 0.99784673]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the expected feature names\n",
    "expected_features = [\n",
    "    'age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol',\n",
    "    'fasting_blood_sugar', 'resting_electrocardiogram', 'max_heart_rate_achieved',\n",
    "    'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia'\n",
    "]\n",
    "\n",
    "# Sample input (corrected to avoid duplicate keys)\n",
    "sample_input = {\n",
    "    'age': 52,\n",
    "    'sex': 1,\n",
    "    'chest_pain_type': 2,\n",
    "    'resting_blood_pressure': 128,\n",
    "    'cholesterol': 205,\n",
    "    'fasting_blood_sugar': 0,\n",
    "    'resting_electrocardiogram': 1,\n",
    "    'max_heart_rate_achieved': 184,\n",
    "    'exercise_induced_angina': 0,\n",
    "    'st_depression': 0.0,\n",
    "    'st_slope': 2,\n",
    "    'num_major_vessels': 0,\n",
    "    'thalassemia': 2\n",
    "}\n",
    "\n",
    "# --- LGBMClassifier Model ---\n",
    "try:\n",
    "    # Load the LGBMClassifier model\n",
    "    lgbm_model = load('models/lgbm_model.pkl')\n",
    "\n",
    "    # Convert sample input to DataFrame\n",
    "    sample_df = pd.DataFrame([sample_input], columns=expected_features)\n",
    "\n",
    "    # Predict\n",
    "    prediction = lgbm_model.predict(sample_df)\n",
    "    prediction_proba = lgbm_model.predict_proba(sample_df)\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Prediction (LGBM): {'Heart Disease' if prediction[0] == 1 else 'No Heart Disease'}\")\n",
    "    print(f\"Prediction Probability (LGBM): {prediction_proba[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or predicting with LGBM model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24a0b0f-6389-4d76-a552-fd006c20de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (LGBM): Heart Disease\n",
      "Prediction Probability (LGBM): [0.00215327 0.99784673]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff3ced-b48b-4045-8132-49343e31eabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
